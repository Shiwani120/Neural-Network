{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICT THE BURNED AREA OF FOREST FIRES WITH NEURAL NETWORKS¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('forestfires.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
       "\n",
       "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0           0         0         0         0         1         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         1         0         0   \n",
       "4           0         0         0         0         1         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         1   \n",
       "\n",
       "     monthoct  monthsep  size_category  \n",
       "0           0         0          small  \n",
       "1           1         0          small  \n",
       "2           1         0          small  \n",
       "3           0         0          small  \n",
       "4           0         0          small  \n",
       "..        ...       ...            ...  \n",
       "512         0         0          large  \n",
       "513         0         0          large  \n",
       "514         0         0          large  \n",
       "515         0         0          small  \n",
       "516         0         0          small  \n",
       "\n",
       "[517 rows x 29 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df.drop(['month','day'],axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['size_category']=lb.fit_transform(df1['size_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 29)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df1.values\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df2[:,0:28]\n",
    "y=df2[:,-1]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=28, activation='relu'))\n",
    "model.add(Dense(28, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "70/70 [==============================] - 2s 10ms/step - loss: 2.3193 - accuracy: 0.6782 - val_loss: 2.1797 - val_accuracy: 0.5497\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.9627 - accuracy: 0.6626 - val_loss: 1.1755 - val_accuracy: 0.6901\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1730 - accuracy: 0.7188 - val_loss: 0.7374 - val_accuracy: 0.6725\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.8060 - val_loss: 0.9155 - val_accuracy: 0.7778\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8558 - val_loss: 0.7355 - val_accuracy: 0.6608\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3329 - accuracy: 0.8972 - val_loss: 0.5485 - val_accuracy: 0.7310\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.8947 - val_loss: 0.5224 - val_accuracy: 0.7544\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2478 - accuracy: 0.9243 - val_loss: 0.5963 - val_accuracy: 0.7076\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2392 - accuracy: 0.9039 - val_loss: 0.3814 - val_accuracy: 0.8538\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2289 - accuracy: 0.9114 - val_loss: 0.8993 - val_accuracy: 0.5673\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2287 - accuracy: 0.8850 - val_loss: 0.2849 - val_accuracy: 0.8830\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9408 - val_loss: 0.2663 - val_accuracy: 0.8772\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.9242 - val_loss: 0.2598 - val_accuracy: 0.9006\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2157 - accuracy: 0.9408 - val_loss: 0.2625 - val_accuracy: 0.8947\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1273 - accuracy: 0.9532 - val_loss: 0.8718 - val_accuracy: 0.5614\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.3158 - accuracy: 0.8702 - val_loss: 0.5736 - val_accuracy: 0.8246\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1851 - accuracy: 0.9304 - val_loss: 0.1855 - val_accuracy: 0.9123\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1957 - accuracy: 0.9232 - val_loss: 0.1904 - val_accuracy: 0.9123\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1345 - accuracy: 0.9594 - val_loss: 0.1700 - val_accuracy: 0.9415\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1280 - accuracy: 0.9653 - val_loss: 0.2044 - val_accuracy: 0.9006\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0850 - accuracy: 0.9618 - val_loss: 0.3115 - val_accuracy: 0.8713\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.8466 - val_loss: 0.2360 - val_accuracy: 0.8830\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0970 - accuracy: 0.9492 - val_loss: 0.2111 - val_accuracy: 0.9240\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0866 - accuracy: 0.9701 - val_loss: 0.1471 - val_accuracy: 0.9474\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9710 - val_loss: 0.2347 - val_accuracy: 0.8889\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1216 - accuracy: 0.9641 - val_loss: 0.2399 - val_accuracy: 0.9240\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1083 - accuracy: 0.9609 - val_loss: 0.1826 - val_accuracy: 0.9006\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0826 - accuracy: 0.9719 - val_loss: 0.1599 - val_accuracy: 0.9123\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9436 - val_loss: 0.1715 - val_accuracy: 0.9474\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9625 - val_loss: 0.1297 - val_accuracy: 0.9474\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9826 - val_loss: 0.1262 - val_accuracy: 0.9474\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0750 - accuracy: 0.9830 - val_loss: 0.1266 - val_accuracy: 0.9415\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9919 - val_loss: 0.1071 - val_accuracy: 0.9532\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9692 - val_loss: 0.1597 - val_accuracy: 0.9181\n",
      "Epoch 35/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0480 - accuracy: 0.9864 - val_loss: 0.2168 - val_accuracy: 0.9064\n",
      "Epoch 36/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.9662 - val_loss: 0.1030 - val_accuracy: 0.9532\n",
      "Epoch 37/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9929 - val_loss: 0.6423 - val_accuracy: 0.8655\n",
      "Epoch 38/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0900 - accuracy: 0.9687 - val_loss: 0.3499 - val_accuracy: 0.8538\n",
      "Epoch 39/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1172 - accuracy: 0.9596 - val_loss: 0.2361 - val_accuracy: 0.9181\n",
      "Epoch 40/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9812 - val_loss: 0.1071 - val_accuracy: 0.9415\n",
      "Epoch 41/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0908 - accuracy: 0.9715 - val_loss: 0.1260 - val_accuracy: 0.9474\n",
      "Epoch 42/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9900 - val_loss: 0.1201 - val_accuracy: 0.9474\n",
      "Epoch 43/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.9846 - val_loss: 0.0913 - val_accuracy: 0.9474\n",
      "Epoch 44/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9903 - val_loss: 0.4277 - val_accuracy: 0.8772\n",
      "Epoch 45/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2761 - accuracy: 0.9071 - val_loss: 0.1404 - val_accuracy: 0.9357\n",
      "Epoch 46/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1316 - accuracy: 0.9391 - val_loss: 0.1357 - val_accuracy: 0.9474\n",
      "Epoch 47/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9852 - val_loss: 1.4622 - val_accuracy: 0.4912\n",
      "Epoch 48/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.9009 - val_loss: 0.1610 - val_accuracy: 0.9357\n",
      "Epoch 49/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9695 - val_loss: 0.0981 - val_accuracy: 0.9474\n",
      "Epoch 50/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.9773 - val_loss: 0.0910 - val_accuracy: 0.9474\n",
      "Epoch 51/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 0.9923 - val_loss: 0.1122 - val_accuracy: 0.9474\n",
      "Epoch 52/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9918 - val_loss: 0.2020 - val_accuracy: 0.9240\n",
      "Epoch 53/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9628 - val_loss: 0.1111 - val_accuracy: 0.9474\n",
      "Epoch 54/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0771 - accuracy: 0.9698 - val_loss: 0.0876 - val_accuracy: 0.9415\n",
      "Epoch 55/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9678 - val_loss: 0.1732 - val_accuracy: 0.9240\n",
      "Epoch 56/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9880 - val_loss: 0.2194 - val_accuracy: 0.9181\n",
      "Epoch 57/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.9033 - val_loss: 0.1807 - val_accuracy: 0.9298\n",
      "Epoch 58/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2562 - accuracy: 0.9137 - val_loss: 1.5833 - val_accuracy: 0.8480\n",
      "Epoch 59/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.9313 - val_loss: 0.0995 - val_accuracy: 0.9415\n",
      "Epoch 60/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0903 - accuracy: 0.9659 - val_loss: 0.1120 - val_accuracy: 0.9415\n",
      "Epoch 61/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 0.9879 - val_loss: 0.4422 - val_accuracy: 0.8713\n",
      "Epoch 62/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9734 - val_loss: 0.1248 - val_accuracy: 0.9532\n",
      "Epoch 63/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9945 - val_loss: 0.1515 - val_accuracy: 0.9357\n",
      "Epoch 64/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1184 - accuracy: 0.9588 - val_loss: 0.3044 - val_accuracy: 0.9064\n",
      "Epoch 65/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 0.9940 - val_loss: 0.1559 - val_accuracy: 0.9415\n",
      "Epoch 66/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9776 - val_loss: 0.3450 - val_accuracy: 0.9064\n",
      "Epoch 67/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9748 - val_loss: 0.2047 - val_accuracy: 0.9240\n",
      "Epoch 68/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9918 - val_loss: 0.3316 - val_accuracy: 0.9064\n",
      "Epoch 69/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0855 - accuracy: 0.9712 - val_loss: 0.2404 - val_accuracy: 0.9123\n",
      "Epoch 70/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9748 - val_loss: 0.3403 - val_accuracy: 0.9064\n",
      "Epoch 71/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9894 - val_loss: 0.7900 - val_accuracy: 0.8012\n",
      "Epoch 72/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0837 - accuracy: 0.9620 - val_loss: 0.1691 - val_accuracy: 0.9240\n",
      "Epoch 73/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.9826 - val_loss: 0.4518 - val_accuracy: 0.8830\n",
      "Epoch 74/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9561 - val_loss: 0.4444 - val_accuracy: 0.9064\n",
      "Epoch 75/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2525 - accuracy: 0.9550 - val_loss: 0.3829 - val_accuracy: 0.9006\n",
      "Epoch 76/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9676 - val_loss: 0.1553 - val_accuracy: 0.9415\n",
      "Epoch 77/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0541 - accuracy: 0.9755 - val_loss: 0.4131 - val_accuracy: 0.9006\n",
      "Epoch 78/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9822 - val_loss: 0.8123 - val_accuracy: 0.7953\n",
      "Epoch 79/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.9698 - val_loss: 0.1296 - val_accuracy: 0.9474\n",
      "Epoch 80/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9810 - val_loss: 0.1278 - val_accuracy: 0.9474\n",
      "Epoch 81/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9983 - val_loss: 0.2223 - val_accuracy: 0.9181\n",
      "Epoch 82/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 0.1616 - val_accuracy: 0.9415\n",
      "Epoch 83/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9861 - val_loss: 0.2169 - val_accuracy: 0.9181\n",
      "Epoch 84/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9988 - val_loss: 0.2478 - val_accuracy: 0.9123\n",
      "Epoch 85/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9998 - val_loss: 0.1469 - val_accuracy: 0.9415\n",
      "Epoch 86/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0550 - accuracy: 0.9704 - val_loss: 0.1618 - val_accuracy: 0.9415\n",
      "Epoch 87/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9808 - val_loss: 0.2394 - val_accuracy: 0.9181\n",
      "Epoch 88/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.9895 - val_loss: 0.2248 - val_accuracy: 0.9240\n",
      "Epoch 89/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9862 - val_loss: 0.2102 - val_accuracy: 0.9357\n",
      "Epoch 90/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9782 - val_loss: 0.3999 - val_accuracy: 0.8947\n",
      "Epoch 91/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9764 - val_loss: 0.2533 - val_accuracy: 0.9240\n",
      "Epoch 92/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9934 - val_loss: 0.3024 - val_accuracy: 0.9064\n",
      "Epoch 93/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9873 - val_loss: 0.1976 - val_accuracy: 0.9298\n",
      "Epoch 94/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9777 - val_loss: 0.3875 - val_accuracy: 0.8889\n",
      "Epoch 95/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9910 - val_loss: 0.2532 - val_accuracy: 0.9123\n",
      "Epoch 96/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1726 - accuracy: 0.9531 - val_loss: 3.7888 - val_accuracy: 0.5029\n",
      "Epoch 97/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1696 - accuracy: 0.9568 - val_loss: 0.1520 - val_accuracy: 0.9532\n",
      "Epoch 98/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.9802 - val_loss: 0.2821 - val_accuracy: 0.9181\n",
      "Epoch 99/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0853 - accuracy: 0.9776 - val_loss: 0.1755 - val_accuracy: 0.9474\n",
      "Epoch 100/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.9871 - val_loss: 0.2518 - val_accuracy: 0.9181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cd4a68a8b0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, validation_split=0.33,epochs=100, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.9652\n",
      "accuracy: 96.52%\n"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(x,y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 36733 instances of 11 sensor measures aggregated over one hour (by means of average or sum) from a gas turbine. \n",
    "The Dataset includes gas turbine parameters (such as Turbine Inlet Temperature and Compressor Discharge pressure) in addition to the ambient variables.\n",
    "\n",
    "\n",
    "\n",
    "Problem statement: predicting turbine energy yield (TEY) using ambient variables as features.\n",
    "\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "The explanations of sensor measurements and their brief statistics are given below.\n",
    "\n",
    "Variable (Abbr.) Unit Min Max Mean\n",
    "Ambient temperature (AT) C â€“6.23 37.10 17.71\n",
    "Ambient pressure (AP) mbar 985.85 1036.56 1013.07\n",
    "Ambient humidity (AH) (%) 24.08 100.20 77.87\n",
    "Air filter difference pressure (AFDP) mbar 2.09 7.61 3.93\n",
    "Gas turbine exhaust pressure (GTEP) mbar 17.70 40.72 25.56\n",
    "Turbine inlet temperature (TIT) C 1000.85 1100.89 1081.43\n",
    "Turbine after temperature (TAT) C 511.04 550.61 546.16\n",
    "Compressor discharge pressure (CDP) mbar 9.85 15.16 12.06\n",
    "Turbine energy yield (TEY) MWH 100.02 179.50 133.51\n",
    "Carbon monoxide (CO) mg/m3 0.00 44.10 2.37\n",
    "Nitrogen oxides (NOx) mg/m3 25.90 119.91 65.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs=pd.read_csv(\"gas_turbines.csv\")\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   6.8594, 1007.9   ,   96.799 , ...,   10.605 ,    3.1547,\n",
       "          82.722 ],\n",
       "       [   6.785 , 1008.4   ,   97.118 , ...,   10.598 ,    3.2363,\n",
       "          82.776 ],\n",
       "       [   6.8977, 1008.8   ,   95.939 , ...,   10.601 ,    3.2012,\n",
       "          82.468 ],\n",
       "       ...,\n",
       "       [   7.2647, 1006.3   ,   99.496 , ...,   10.483 ,    7.9632,\n",
       "          90.912 ],\n",
       "       [   7.006 , 1006.8   ,   99.008 , ...,   10.533 ,    6.2494,\n",
       "          93.227 ],\n",
       "       [   6.9279, 1007.2   ,   97.533 , ...,   10.583 ,    4.9816,\n",
       "          92.498 ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1=gs.values\n",
    "gs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   6.8594, 1007.9   ,   96.799 , ...,   10.605 ,    3.1547,\n",
       "          82.722 ],\n",
       "       [   6.785 , 1008.4   ,   97.118 , ...,   10.598 ,    3.2363,\n",
       "          82.776 ],\n",
       "       [   6.8977, 1008.8   ,   95.939 , ...,   10.601 ,    3.2012,\n",
       "          82.468 ],\n",
       "       ...,\n",
       "       [   7.2647, 1006.3   ,   99.496 , ...,   10.483 ,    7.9632,\n",
       "          90.912 ],\n",
       "       [   7.006 , 1006.8   ,   99.008 , ...,   10.533 ,    6.2494,\n",
       "          93.227 ],\n",
       "       [   6.9279, 1007.2   ,   97.533 , ...,   10.583 ,    4.9816,\n",
       "          92.498 ]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=gs1[:,[0,1,2,3,4,5,6,8,9,10]]\n",
    "Y=gs1[:,-4]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.25,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=MinMaxScaler()\n",
    "scaler.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.53182072e-02, -2.08996080e+01, -4.40409381e-01, ...,\n",
       "        -2.27018017e+00,  7.12530532e-06, -3.04932831e-01],\n",
       "       [-1.51554089e-02, -2.08995283e+01, -4.40448350e-01, ...,\n",
       "        -2.26692897e+00,  5.80370091e-06, -3.04938865e-01],\n",
       "       [-1.50348875e-02, -2.08995525e+01, -4.40484356e-01, ...,\n",
       "        -2.27736739e+00,  7.07225483e-05, -3.04950135e-01],\n",
       "       ...,\n",
       "       [-1.53686106e-02, -2.08995740e+01, -4.40403080e-01, ...,\n",
       "        -2.25398187e+00, -8.55365770e-06, -3.04941186e-01],\n",
       "       [-1.50773855e-02, -2.08996286e+01, -4.40493189e-01, ...,\n",
       "        -2.28115204e+00,  4.39928881e-05, -3.04946670e-01],\n",
       "       [-1.53268738e-02, -2.08996782e+01, -4.40430209e-01, ...,\n",
       "        -2.27006483e+00, -4.94611135e-06, -3.04926107e-01]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=scaler.transform(x_train)\n",
    "x_test=scaler.transform(x_test)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "# add nodes for prediction\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "353/353 [==============================] - 3s 2ms/step - loss: 13209.3097\n",
      "Epoch 2/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.3024\n",
      "Epoch 3/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 261.2177\n",
      "Epoch 4/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 259.2586\n",
      "Epoch 5/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 262.7736\n",
      "Epoch 6/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 248.8115\n",
      "Epoch 7/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.9711\n",
      "Epoch 8/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.6602\n",
      "Epoch 9/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 256.1399\n",
      "Epoch 10/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 256.3066\n",
      "Epoch 11/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.5144\n",
      "Epoch 12/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.0524\n",
      "Epoch 13/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.3054\n",
      "Epoch 14/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 256.0949\n",
      "Epoch 15/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 256.8971\n",
      "Epoch 16/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.9572\n",
      "Epoch 17/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 263.9431\n",
      "Epoch 18/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.9563\n",
      "Epoch 19/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.5573\n",
      "Epoch 20/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.2986\n",
      "Epoch 21/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.4104\n",
      "Epoch 22/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 260.6906\n",
      "Epoch 23/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 256.9576\n",
      "Epoch 24/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.4156\n",
      "Epoch 25/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 259.7314\n",
      "Epoch 26/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 257.4816\n",
      "Epoch 27/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 259.1706\n",
      "Epoch 28/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 256.9029\n",
      "Epoch 29/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.3820\n",
      "Epoch 30/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 256.0448\n",
      "Epoch 31/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.2854\n",
      "Epoch 32/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.6407\n",
      "Epoch 33/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 258.2052\n",
      "Epoch 34/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 256.2637\n",
      "Epoch 35/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 256.2236\n",
      "Epoch 36/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.6093\n",
      "Epoch 37/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.8430\n",
      "Epoch 38/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 257.0542\n",
      "Epoch 39/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.4949\n",
      "Epoch 40/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 257.8913\n",
      "Epoch 41/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.9718\n",
      "Epoch 42/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.6637\n",
      "Epoch 43/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.5087\n",
      "Epoch 44/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 262.5098\n",
      "Epoch 45/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.8386\n",
      "Epoch 46/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.4860\n",
      "Epoch 47/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.6967\n",
      "Epoch 48/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.2767\n",
      "Epoch 49/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.5771\n",
      "Epoch 50/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.9947\n",
      "Epoch 51/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.2751\n",
      "Epoch 52/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 257.5155\n",
      "Epoch 53/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 258.1614\n",
      "Epoch 54/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 248.5846\n",
      "Epoch 55/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.2521\n",
      "Epoch 56/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.3312\n",
      "Epoch 57/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 257.4603\n",
      "Epoch 58/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.5151\n",
      "Epoch 59/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.2033\n",
      "Epoch 60/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 258.9176\n",
      "Epoch 61/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.1793\n",
      "Epoch 62/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.0342\n",
      "Epoch 63/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 259.5398\n",
      "Epoch 64/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.1650\n",
      "Epoch 65/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 258.1986\n",
      "Epoch 66/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.6359\n",
      "Epoch 67/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 258.9932\n",
      "Epoch 68/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.7269\n",
      "Epoch 69/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 248.9426\n",
      "Epoch 70/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.5501\n",
      "Epoch 71/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.5813\n",
      "Epoch 72/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.3956\n",
      "Epoch 73/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.9056\n",
      "Epoch 74/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.9025\n",
      "Epoch 75/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.4171\n",
      "Epoch 76/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 258.2607\n",
      "Epoch 77/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 258.0827\n",
      "Epoch 78/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.2647\n",
      "Epoch 79/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.6778\n",
      "Epoch 80/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.3451\n",
      "Epoch 81/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.5973\n",
      "Epoch 82/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.8608\n",
      "Epoch 83/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.4701\n",
      "Epoch 84/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 258.6975\n",
      "Epoch 85/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.1672\n",
      "Epoch 86/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 257.0890\n",
      "Epoch 87/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.5482\n",
      "Epoch 88/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.8972\n",
      "Epoch 89/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.4800\n",
      "Epoch 90/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.7077\n",
      "Epoch 91/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.9023\n",
      "Epoch 92/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.6757\n",
      "Epoch 93/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.6161\n",
      "Epoch 94/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 259.1634\n",
      "Epoch 95/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.3342\n",
      "Epoch 96/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.0228\n",
      "Epoch 97/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.5611\n",
      "Epoch 98/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.0025\n",
      "Epoch 99/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.5378\n",
      "Epoch 100/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.1520\n",
      "Epoch 101/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 257.1921\n",
      "Epoch 102/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.5379\n",
      "Epoch 103/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.3661\n",
      "Epoch 104/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.9953\n",
      "Epoch 105/250\n",
      "353/353 [==============================] - 1s 1ms/step - loss: 257.8898\n",
      "Epoch 106/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 247.9449\n",
      "Epoch 107/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.9112\n",
      "Epoch 108/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 258.5669\n",
      "Epoch 109/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.8056\n",
      "Epoch 110/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.6689\n",
      "Epoch 111/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.3732\n",
      "Epoch 112/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.4692\n",
      "Epoch 113/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.9891\n",
      "Epoch 114/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 260.1387\n",
      "Epoch 115/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 256.1430\n",
      "Epoch 116/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.7154\n",
      "Epoch 117/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 258.5795\n",
      "Epoch 118/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.5693\n",
      "Epoch 119/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.0838\n",
      "Epoch 120/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.4135\n",
      "Epoch 121/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.0275\n",
      "Epoch 122/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.6998\n",
      "Epoch 123/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.5519\n",
      "Epoch 124/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 247.3570\n",
      "Epoch 125/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.7335\n",
      "Epoch 126/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.1664\n",
      "Epoch 127/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.5280\n",
      "Epoch 128/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.5690\n",
      "Epoch 129/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.5490\n",
      "Epoch 130/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.7035\n",
      "Epoch 131/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.0711\n",
      "Epoch 132/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.9362\n",
      "Epoch 133/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.5496\n",
      "Epoch 134/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.9348\n",
      "Epoch 135/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.4841\n",
      "Epoch 136/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 256.3227\n",
      "Epoch 137/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 256.2048\n",
      "Epoch 138/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.6840\n",
      "Epoch 139/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.4291\n",
      "Epoch 140/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.2695\n",
      "Epoch 141/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 258.7691\n",
      "Epoch 142/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.4352\n",
      "Epoch 143/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.1474\n",
      "Epoch 144/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.6392\n",
      "Epoch 145/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.4267\n",
      "Epoch 146/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 248.7370\n",
      "Epoch 147/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.0319\n",
      "Epoch 148/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 248.1867\n",
      "Epoch 149/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.4098\n",
      "Epoch 150/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.3713\n",
      "Epoch 151/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 248.7972\n",
      "Epoch 152/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.6685\n",
      "Epoch 153/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.1514\n",
      "Epoch 154/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.3364\n",
      "Epoch 155/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 247.7953\n",
      "Epoch 156/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.7812\n",
      "Epoch 157/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.3196\n",
      "Epoch 158/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.2486\n",
      "Epoch 159/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 259.0426\n",
      "Epoch 160/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 259.9407\n",
      "Epoch 161/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.9306\n",
      "Epoch 162/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 247.5027\n",
      "Epoch 163/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.8217\n",
      "Epoch 164/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.3151\n",
      "Epoch 165/250\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 253.8746\n",
      "Epoch 166/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 247.7461\n",
      "Epoch 167/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.7144\n",
      "Epoch 168/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 256.4347\n",
      "Epoch 169/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.8438\n",
      "Epoch 170/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.7979\n",
      "Epoch 171/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 256.4079\n",
      "Epoch 172/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.2562\n",
      "Epoch 173/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.8411\n",
      "Epoch 174/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.4231\n",
      "Epoch 175/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.1252\n",
      "Epoch 176/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.5514\n",
      "Epoch 177/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.5488\n",
      "Epoch 178/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.9267\n",
      "Epoch 179/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.6176\n",
      "Epoch 180/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.2842\n",
      "Epoch 181/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.0218\n",
      "Epoch 182/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.6446\n",
      "Epoch 183/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 255.9228\n",
      "Epoch 184/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 247.5298\n",
      "Epoch 185/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.9299\n",
      "Epoch 186/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 248.2460\n",
      "Epoch 187/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.9801\n",
      "Epoch 188/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 245.8841\n",
      "Epoch 189/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 246.6484\n",
      "Epoch 190/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.9834\n",
      "Epoch 191/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.6505\n",
      "Epoch 192/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 248.7872\n",
      "Epoch 193/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.3102\n",
      "Epoch 194/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 248.6261\n",
      "Epoch 195/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.4336\n",
      "Epoch 196/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 248.4924\n",
      "Epoch 197/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.1136\n",
      "Epoch 198/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.2420\n",
      "Epoch 199/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 248.3473\n",
      "Epoch 200/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.9695\n",
      "Epoch 201/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.2876\n",
      "Epoch 202/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 245.6277\n",
      "Epoch 203/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.1390\n",
      "Epoch 204/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.9814\n",
      "Epoch 205/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.9575\n",
      "Epoch 206/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.6298\n",
      "Epoch 207/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 248.8146\n",
      "Epoch 208/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 251.7576\n",
      "Epoch 209/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.9880\n",
      "Epoch 210/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.3380\n",
      "Epoch 211/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 247.2036\n",
      "Epoch 212/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.7906\n",
      "Epoch 213/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 253.9252\n",
      "Epoch 214/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 247.4530\n",
      "Epoch 215/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.5946\n",
      "Epoch 216/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 244.6238\n",
      "Epoch 217/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 247.4786\n",
      "Epoch 218/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 252.5612\n",
      "Epoch 219/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.4748\n",
      "Epoch 220/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 248.7887\n",
      "Epoch 221/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 244.7931\n",
      "Epoch 222/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.3477\n",
      "Epoch 223/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.0224\n",
      "Epoch 224/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 247.4082\n",
      "Epoch 225/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 248.7294\n",
      "Epoch 226/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 250.6192\n",
      "Epoch 227/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 254.2000\n",
      "Epoch 228/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 243.5992\n",
      "Epoch 229/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 243.9230\n",
      "Epoch 230/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 249.5123\n",
      "Epoch 231/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 245.3431\n",
      "Epoch 232/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 245.8596\n",
      "Epoch 233/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 239.9764\n",
      "Epoch 234/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 238.9889\n",
      "Epoch 235/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 244.2650\n",
      "Epoch 236/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 247.6580\n",
      "Epoch 237/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 243.5151\n",
      "Epoch 238/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 242.2770\n",
      "Epoch 239/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 240.0404\n",
      "Epoch 240/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 241.7843\n",
      "Epoch 241/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 243.8462\n",
      "Epoch 242/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 236.5379\n",
      "Epoch 243/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 243.8109\n",
      "Epoch 244/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 246.0347\n",
      "Epoch 245/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 238.9993\n",
      "Epoch 246/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 242.5535\n",
      "Epoch 247/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 241.2841\n",
      "Epoch 248/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 237.7628\n",
      "Epoch 249/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 237.2740\n",
      "Epoch 250/250\n",
      "353/353 [==============================] - 1s 2ms/step - loss: 237.6032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cd4a273910>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(x_train, y_train, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as plot\n",
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[135.07776],\n",
       "       [135.39783],\n",
       "       [134.20406],\n",
       "       ...,\n",
       "       [136.38391],\n",
       "       [134.45956],\n",
       "       [135.06517]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224.51783752441406"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = model.evaluate(x_test,y_test,verbose=0)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.757188878160841"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224.5178538304452"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1cd51c8e0d0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
